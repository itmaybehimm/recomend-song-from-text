{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dda5280-17fa-4830-9b78-f055e4507506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21929b9-4dc4-473e-bcd5-f26396d5643e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tweet_emotions_2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac84cba-f94e-4a07-ba90-da133b526715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  object\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ac9f5f-0676-439f-a32c-de699e5eacc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd96ca-c7a5-4215-bf79-c2a95cc97cbc",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b7c4303a-650b-4c76-8183-e0d261a608dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_1(text):\n",
    "    #removing @ tags \n",
    "    text=re.sub(r'@[a-zA-z0-9]+\\s*',' ',str(text))\n",
    "    \n",
    "    #removing urls\n",
    "    text=re.sub(r'http\\S+', '', text)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #replacing multiple whitesapces by a single\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    \n",
    "    # remove all single characters(surrounded by whitespace)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # remove all single characters except i and I (surrounded by whitespace)\n",
    "    # text = re.sub(r'\\s+(?![iI])[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    \n",
    "    # Converting to Lowercase \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Lemmatization- splits into list of words ['The', 'quick', ....]\n",
    "    text = text.split()\n",
    "\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2e154c59-51ea-4e9f-ba61-9e1c95d251f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(clean_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d98061-5a42-4e0c-add8-b97222b86132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1559c-ceee-4b50-a472-3bb644250327",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stop words are common enginlish words that dont contain too much information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1e8a10-f5d2-41e1-8eac-c58ad185818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return len(set(words) & stop_words)\n",
    "\n",
    "def list_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return list(set(words) & stop_words)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Get the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords from the text\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Recreate the text without stopwords\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686cf3cd-e307-4459-ba4c-d1840ffaf77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  stop_words\n",
       "0                            i didnt feel humiliated      0           1\n",
       "1  i can go from feeling so hopeless to so damned...      0          10\n",
       "2   im grabbing a minute to post i feel greedy wrong      3           3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2           9\n",
       "4                               i am feeling grouchy      3           2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Add a new col 'stop_words' that contains the count of stopwords\n",
    "df['stop_words'] = df['text'].apply(count_stopwords)\n",
    "value_counts = df['stop_words'].value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c1456d-44a1-49c6-8882-174ae0675e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       " 9,\n",
       " ['it', 'am', 'i', 'on', 'will', 'the', 'that', 'about', 'is'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets examine a row \n",
    "df.iloc[3]['text'],df.iloc[3]['stop_words'],list_stopwords(df.iloc[3]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc630c8-9308-4a03-8b3a-1258b30483dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  stop_words\n",
       "0                              didnt feel humiliated      0           1\n",
       "1  go feeling hopeless damned hopeful around some...      0          10\n",
       "2          im grabbing minute post feel greedy wrong      3           3\n",
       "3  ever feeling nostalgic fireplace know still pr...      2           9\n",
       "4                                    feeling grouchy      3           2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b76b88-0bd5-4484-871c-695d44335492",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a32e86-bc6e-490e-a884-e3b81141a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_2(text):\n",
    "    #converting special character and numbers to whitespaces\n",
    "    text = re.sub(r'\\W+',' ',text)\n",
    "    text=re.sub(r'\\d+', '', text)\n",
    "    #replacing multiple whitesapces by a single\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    \n",
    "    # remove all single characters(surrounded by whitespace)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # remove all single characters except i and I (surrounded by whitespace)\n",
    "    # text = re.sub(r'\\s+(?![iI])[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    \n",
    "    # Converting to Lowercase \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Lemmatization- splits into list of words ['The', 'quick', ....]\n",
    "    text = text.split()\n",
    "\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7e1d99-041a-4a01-bcac-96c97e6458bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Cleaning \n",
    "# cleaned = []\n",
    "\n",
    "# for i in range(0, len(X)):\n",
    "    \n",
    "#     #removing @ tags\n",
    "#     text=re.sub(r'@[a-zA-z0-9]+\\s*',' ',str(X.iloc[i]))\n",
    "    \n",
    "#     #removing urls\n",
    "#     text=re.sub(r'http\\S+', '', text)\n",
    "#     text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "#     #converting special character and numbers to whitespaces\n",
    "#     text = re.sub(r'\\W+',' ',text)\n",
    "    \n",
    "#     #replacing multiple whitesapces by a single\n",
    "#     text = re.sub(r'\\s+',' ',text)\n",
    "    \n",
    "#     # remove all single characters(surrounded by whitespace)\n",
    "#     text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "#     # remove all single characters except i and I (surrounded by whitespace)\n",
    "#     # text = re.sub(r'\\s+(?![iI])[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    \n",
    "#     # Converting to Lowercase \n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # Lemmatization- splits into list of words ['The', 'quick', ....]\n",
    "#     text = text.split()\n",
    "\n",
    "#     lemma = WordNetLemmatizer()\n",
    "#     text = [lemma.lemmatize(word) for word in text]\n",
    "#     text = ' '.join(text)\n",
    "    \n",
    "#     cleaned.append(text)\n",
    "# print(cleaned[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd5a442-6ff0-42a4-b506-7b9ee857ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making sure that cleaned data has the same length as X\n",
    "# len(cleaned), len(X),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3579f705-c3ad-4c34-971a-1d4e0480e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  stop_words\n",
       "0                              didnt feel humiliated      0           1\n",
       "1  go feeling hopeless damned hopeful around some...      0          10\n",
       "2          im grabbing minute post feel greedy wrong      3           3\n",
       "3  ever feeling nostalgic fireplace know still pr...      2           9\n",
       "4                                    feeling grouchy      3           2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_text_2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96788f41-a4f0-4e8e-8a8a-67c07ca2881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  stop_words\n",
       "0                              didnt feel humiliated      0           1\n",
       "1  go feeling hopeless damned hopeful around some...      0          10\n",
       "2          im grabbing minute post feel greedy wrong      3           3\n",
       "3  ever feeling nostalgic fireplace know still pr...      2           9\n",
       "4                                    feeling grouchy      3           2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a11138-2676-4710-9640-7fdaa9f1a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('think easiest time year feel dissatisfied', 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets examine a row \n",
    "i=12\n",
    "df.iloc[i]['text'],df.iloc[i]['stop_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a5445f92-d2df-4087-8089-3c2a533b78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song-recomendation-kernel",
   "language": "python",
   "name": "song-recomendation-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
